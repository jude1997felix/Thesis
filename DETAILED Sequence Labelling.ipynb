{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prostate-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, ClassLabel, Value\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ranking-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okay</td>\n",
       "      <td>B-dm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maybe</td>\n",
       "      <td>B-st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>before you get to</td>\n",
       "      <td>B-dir I-dir I-dir I-dir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>I-dir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it is</td>\n",
       "      <td>B-shape I-shape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tokens                     tags\n",
       "0               okay                     B-dm\n",
       "1              Maybe                     B-st\n",
       "2  before you get to  B-dir I-dir I-dir I-dir\n",
       "3          Australia                    I-dir\n",
       "4              it is          B-shape I-shape"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DETAILED_train_test_combined_seq_v0.0.txt', sep = \"\\t\", names = ['tokens','tags'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "speaking-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[okay]</td>\n",
       "      <td>[B-dm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Maybe]</td>\n",
       "      <td>[B-st]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[before, you, get, to]</td>\n",
       "      <td>[B-dir, I-dir, I-dir, I-dir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Australia]</td>\n",
       "      <td>[I-dir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[it, is]</td>\n",
       "      <td>[B-shape, I-shape]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tokens                          tags\n",
       "0                  [okay]                        [B-dm]\n",
       "1                 [Maybe]                        [B-st]\n",
       "2  [before, you, get, to]  [B-dir, I-dir, I-dir, I-dir]\n",
       "3             [Australia]                       [I-dir]\n",
       "4                [it, is]            [B-shape, I-shape]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['tokens'].str.split(' ')\n",
    "df['tags'] = df['tags'].str.split(' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "varied-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6781"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "white-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df['tokens'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "announced-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {'B-abdnd': 1,\n",
    " 'B-ack': 2,\n",
    " 'B-ad': 3,\n",
    " 'B-an': 4,\n",
    " 'B-apo': 5,\n",
    " 'B-app': 6,\n",
    " 'B-ay': 7,\n",
    " 'B-contin': 8,\n",
    " 'B-crit': 9,\n",
    " 'B-dir': 10,\n",
    " 'B-disapp': 11,\n",
    " 'B-dm': 12,\n",
    " 'B-dntknw': 13,\n",
    " 'B-greet': 14,\n",
    " 'B-lndmrk': 15,\n",
    " 'B-off': 16,\n",
    " 'B-qo': 17,\n",
    " 'B-qwh': 18,\n",
    " 'B-qyn': 19,\n",
    " 'B-shape': 20,\n",
    " 'B-size': 21,\n",
    " 'B-st': 22,\n",
    " 'B-thank': 23,\n",
    " 'B-wrng': 24,\n",
    " 'I-abdnd': 25,\n",
    " 'I-ack': 26,\n",
    " 'I-ad': 27,\n",
    " 'I-an': 28,\n",
    " 'I-apo': 29,\n",
    " 'I-app': 30,\n",
    " 'I-ay': 31,\n",
    " 'I-contin': 32,\n",
    " 'I-crit': 33,\n",
    " 'I-dir': 34,\n",
    " 'I-disapp': 35,\n",
    " 'I-dm': 36,\n",
    " 'I-dntknw': 37,\n",
    " 'I-greet': 38,\n",
    " 'I-lndmrk': 39,\n",
    " 'I-off': 40,\n",
    " 'I-qo': 41,\n",
    " 'I-qwh': 42,\n",
    " 'I-qyn': 43,\n",
    " 'I-shape': 44,\n",
    " 'I-size': 45,\n",
    " 'I-st': 46,\n",
    " 'I-thank': 47,\n",
    " 'I-wrng': 48}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "drawn-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[okay]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Maybe]</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[before, you, get, to]</td>\n",
       "      <td>[10, 34, 34, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Australia]</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[it, is]</td>\n",
       "      <td>[20, 44]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tokens              tags\n",
       "0                  [okay]              [12]\n",
       "1                 [Maybe]              [22]\n",
       "2  [before, you, get, to]  [10, 34, 34, 34]\n",
       "3             [Australia]              [34]\n",
       "4                [it, is]          [20, 44]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,_ in enumerate(df.tags):\n",
    "    if i == 6297:\n",
    "        continue\n",
    "    elif i == 6594:\n",
    "        continue\n",
    "    else:\n",
    "        df.tags[i] = [tag_dict[item] for item in df.tags[i]]\n",
    "    \n",
    "df.tags[6779] = [tag_dict[item] for item in df.tags[6779]]\n",
    "df.tags[6780] = [tag_dict[item] for item in df.tags[6780]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lightweight-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_1D(series):\n",
    " return pd.Series([x for _list in series for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "opposite-occupation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34    9155\n",
       "44    4528\n",
       "32    3907\n",
       "39    2574\n",
       "43    2167\n",
       "10    2119\n",
       "40    1306\n",
       "45     904\n",
       "8      894\n",
       "20     790\n",
       "25     659\n",
       "12     566\n",
       "2      559\n",
       "15     515\n",
       "19     454\n",
       "7      414\n",
       "1      380\n",
       "46     371\n",
       "48     313\n",
       "37     294\n",
       "16     269\n",
       "31     258\n",
       "21     254\n",
       "26     249\n",
       "27     180\n",
       "6      167\n",
       "4      144\n",
       "42     142\n",
       "30     119\n",
       "36     118\n",
       "22     109\n",
       "41      96\n",
       "24      93\n",
       "28      86\n",
       "35      84\n",
       "3       81\n",
       "13      58\n",
       "18      51\n",
       "29      50\n",
       "5       34\n",
       "17      27\n",
       "11      24\n",
       "33      21\n",
       "38      21\n",
       "14      15\n",
       "9       10\n",
       "23       9\n",
       "47       8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_1D(df['tags']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "informational-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['B-abdnd', 'B-ack', 'B-ad', 'B-an', 'B-apo', 'B-app', 'B-ay', 'B-contin', 'B-crit', 'B-dir', 'B-disapp',\n",
    " 'B-dm', 'B-dntknw', 'B-greet', 'B-lndmrk', 'B-off', 'B-qo', 'B-qwh', 'B-qyn', 'B-shape', 'B-size', 'B-st',\n",
    " 'B-thank', 'B-wrng', 'I-abdnd', 'I-ack', 'I-ad', 'I-an', 'I-apo', 'I-app', 'I-ay', 'I-contin', 'I-crit',\n",
    " 'I-dir', 'I-disapp', 'I-dm', 'I-dntknw', 'I-greet', 'I-lndmrk', 'I-off', 'I-qo', 'I-qwh', 'I-qyn', 'I-shape',\n",
    " 'I-size', 'I-st', 'I-thank', 'I-wrng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitting-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "german-brazil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 949\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_all = Dataset.from_pandas(df, features=Features({\n",
    "                \"tokens\": Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
    "                \"tags\": Sequence(feature=ClassLabel(num_classes=len(tags), names=tags, names_file=None, id=None), length=-1, id=None)\n",
    "            })).train_test_split(test_size=0.2)\n",
    "train_test = ds_all[\"test\"].train_test_split(test_size=0.3)\n",
    "test_validation = train_test[\"test\"].train_test_split(test_size=0.5)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"test\": test_validation[\"train\"],\n",
    "    \"validation\": test_validation[\"test\"]})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incoming-acting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'tags': Sequence(feature=ClassLabel(num_classes=48, names=['B-abdnd', 'B-ack', 'B-ad', 'B-an', 'B-apo', 'B-app', 'B-ay', 'B-contin', 'B-crit', 'B-dir', 'B-disapp', 'B-dm', 'B-dntknw', 'B-greet', 'B-lndmrk', 'B-off', 'B-qo', 'B-qwh', 'B-qyn', 'B-shape', 'B-size', 'B-st', 'B-thank', 'B-wrng', 'I-abdnd', 'I-ack', 'I-ad', 'I-an', 'I-apo', 'I-app', 'I-ay', 'I-contin', 'I-crit', 'I-dir', 'I-disapp', 'I-dm', 'I-dntknw', 'I-greet', 'I-lndmrk', 'I-off', 'I-qo', 'I-qwh', 'I-qyn', 'I-shape', 'I-size', 'I-st', 'I-thank', 'I-wrng'], names_file=None, id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "settled-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "documented-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "permanent-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "creative-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "#     print('Works1')\n",
    "#     print(examples['tokens'])\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"],  is_split_into_words=True)\n",
    "#     print('Works2')\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wireless-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "saved-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [10, 34, 34, 34, 34], 'tokens': ['to', 'the', 'left', 'of', 'Russia']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][1]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mathematical-sample",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prompt-packet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'to', 'the', 'left', 'of', 'russia', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opening-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[\"train\"][2]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "digital-fortune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example[\"tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "played-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "available-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e954845ad842199989223b620b6b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a33f65eadf4458bb70b41a924efe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd8a7850a3e4385bdbeedf74130ee18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fourth-attitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'tags', 'tokens'],\n",
       "        num_rows: 949\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'tags', 'tokens'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'tags', 'tokens'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "strange-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 16, 40, 40, 40, 40, 40, 40, -100]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test']['labels'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "legendary-seller",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(tags)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "supreme-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'pos'\n",
    "args = TrainingArguments(\n",
    "    f\"test-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "empty-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "saving-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForTokenClassification(tokenizer=PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "north-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_more = load_metric(\"seqeval\")\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "painted-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for i,_ in enumerate(predictions):\n",
    "        for j,_ in enumerate(predictions[i]):\n",
    "            if labels[i][j] != -100:\n",
    "                true_predictions.append([tags[predictions[i][j]-1]])\n",
    "                true_labels.append([tags[labels[i][j]-1]])\n",
    "    results = metric_more.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accredited-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "anticipated-chemistry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ay': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [tags[i-1] for i in example[\"tags\"]]\n",
    "metric_more.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "latest-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 19:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.355659</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>0.417355</td>\n",
       "      <td>2.917800</td>\n",
       "      <td>69.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.869172</td>\n",
       "      <td>0.652066</td>\n",
       "      <td>0.652066</td>\n",
       "      <td>0.652066</td>\n",
       "      <td>0.565289</td>\n",
       "      <td>2.898200</td>\n",
       "      <td>70.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.727398</td>\n",
       "      <td>0.661983</td>\n",
       "      <td>0.661983</td>\n",
       "      <td>0.661983</td>\n",
       "      <td>0.595868</td>\n",
       "      <td>2.939100</td>\n",
       "      <td>69.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.675676</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.608264</td>\n",
       "      <td>2.994100</td>\n",
       "      <td>68.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.628709</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.617355</td>\n",
       "      <td>2.993700</td>\n",
       "      <td>68.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.613049</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.628926</td>\n",
       "      <td>2.932300</td>\n",
       "      <td>69.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.644759</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.677686</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>2.935400</td>\n",
       "      <td>69.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.627379</td>\n",
       "      <td>0.680992</td>\n",
       "      <td>0.680992</td>\n",
       "      <td>0.680992</td>\n",
       "      <td>0.633058</td>\n",
       "      <td>3.018100</td>\n",
       "      <td>67.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.616283</td>\n",
       "      <td>0.687603</td>\n",
       "      <td>0.687603</td>\n",
       "      <td>0.687603</td>\n",
       "      <td>0.642975</td>\n",
       "      <td>3.016300</td>\n",
       "      <td>67.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.646366</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.634711</td>\n",
       "      <td>2.955700</td>\n",
       "      <td>69.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.643767</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.678512</td>\n",
       "      <td>0.637190</td>\n",
       "      <td>2.967600</td>\n",
       "      <td>68.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.637190</td>\n",
       "      <td>3.197200</td>\n",
       "      <td>63.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.658356</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.680165</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>2.968100</td>\n",
       "      <td>68.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.654776</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.637190</td>\n",
       "      <td>2.943800</td>\n",
       "      <td>69.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.265200</td>\n",
       "      <td>1.661266</td>\n",
       "      <td>0.682645</td>\n",
       "      <td>0.682645</td>\n",
       "      <td>0.682645</td>\n",
       "      <td>0.637190</td>\n",
       "      <td>2.964700</td>\n",
       "      <td>68.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jude/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.8828799777560764, metrics={'train_runtime': 1178.4858, 'train_samples_per_second': 0.764, 'total_flos': 113823044859468.0, 'epoch': 15.0, 'init_mem_cpu_alloc_delta': 118412, 'init_mem_cpu_peaked_delta': 18454, 'train_mem_cpu_alloc_delta': 155521, 'train_mem_cpu_peaked_delta': 8295583})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "turned-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6612659692764282,\n",
       " 'eval_precision': 0.6826446280991736,\n",
       " 'eval_recall': 0.6826446280991736,\n",
       " 'eval_f1': 0.6826446280991736,\n",
       " 'eval_accuracy': 0.6371900826446281,\n",
       " 'eval_runtime': 3.7004,\n",
       " 'eval_samples_per_second': 55.129,\n",
       " 'epoch': 15.0,\n",
       " 'eval_mem_cpu_alloc_delta': 1181040,\n",
       " 'eval_mem_cpu_peaked_delta': 1342028}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hollow-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "significant-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = []\n",
    "true_labels = []\n",
    "for i,_ in enumerate(predictions):\n",
    "    for j,_ in enumerate(predictions[i]):\n",
    "        if labels[i][j] != -100:\n",
    "            true_predictions.append([tags[predictions[i][j]-1]])\n",
    "            true_labels.append([tags[labels[i][j]-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "brave-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abdnd': {'precision': 0.17647058823529413,\n",
       "  'recall': 0.34615384615384615,\n",
       "  'f1': 0.23376623376623376,\n",
       "  'number': 26},\n",
       " 'ack': {'precision': 0.41818181818181815,\n",
       "  'recall': 0.575,\n",
       "  'f1': 0.4842105263157894,\n",
       "  'number': 40},\n",
       " 'ad': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 6},\n",
       " 'an': {'precision': 1.0,\n",
       "  'recall': 0.4444444444444444,\n",
       "  'f1': 0.6153846153846153,\n",
       "  'number': 9},\n",
       " 'apo': {'precision': 0.8,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.888888888888889,\n",
       "  'number': 4},\n",
       " 'app': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.13333333333333333,\n",
       "  'f1': 0.2222222222222222,\n",
       "  'number': 15},\n",
       " 'ay': {'precision': 0.40540540540540543,\n",
       "  'recall': 0.4411764705882353,\n",
       "  'f1': 0.4225352112676056,\n",
       "  'number': 34},\n",
       " 'contin': {'precision': 0.6481481481481481,\n",
       "  'recall': 0.5343511450381679,\n",
       "  'f1': 0.5857740585774058,\n",
       "  'number': 131},\n",
       " 'dir': {'precision': 0.7576470588235295,\n",
       "  'recall': 0.9096045197740112,\n",
       "  'f1': 0.8267008985879332,\n",
       "  'number': 354},\n",
       " 'disapp': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5},\n",
       " 'dm': {'precision': 0.5555555555555556,\n",
       "  'recall': 0.22727272727272727,\n",
       "  'f1': 0.3225806451612903,\n",
       "  'number': 22},\n",
       " 'greet': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'lndmrk': {'precision': 0.32941176470588235,\n",
       "  'recall': 0.36363636363636365,\n",
       "  'f1': 0.345679012345679,\n",
       "  'number': 77},\n",
       " 'off': {'precision': 0.48148148148148145,\n",
       "  'recall': 0.2857142857142857,\n",
       "  'f1': 0.3586206896551724,\n",
       "  'number': 91},\n",
       " 'qo': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5},\n",
       " 'qwh': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.15384615384615385,\n",
       "  'f1': 0.25,\n",
       "  'number': 13},\n",
       " 'qyn': {'precision': 0.7,\n",
       "  'recall': 0.835820895522388,\n",
       "  'f1': 0.7619047619047619,\n",
       "  'number': 67},\n",
       " 'shape': {'precision': 0.897196261682243,\n",
       "  'recall': 0.8205128205128205,\n",
       "  'f1': 0.8571428571428571,\n",
       "  'number': 234},\n",
       " 'size': {'precision': 0.65625,\n",
       "  'recall': 0.9545454545454546,\n",
       "  'f1': 0.7777777777777778,\n",
       "  'number': 22},\n",
       " 'st': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 5},\n",
       " 'wrng': {'precision': 1.0,\n",
       "  'recall': 0.15789473684210525,\n",
       "  'f1': 0.2727272727272727,\n",
       "  'number': 19},\n",
       " 'overall_precision': 0.6627118644067796,\n",
       " 'overall_recall': 0.6627118644067796,\n",
       " 'overall_f1': 0.6627118644067796,\n",
       " 'overall_accuracy': 0.6313559322033898}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = metric_more.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "outdoor-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model('detailed_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
